{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HELLO World:\n",
    "- Install tensorflow and opencv-python\n",
    "- Load the mnist data for handwritten digits, both the *training samples: 60k* and *testing samples: 10k*\n",
    "- tensorflow already contains mnist data which can be loaded using the keras api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist # this is the dataset for handwritten digits 0-9 based on 28x28 sized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unpack the dataset into train and test dataset\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot a graph to see how the data looks like\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the values of each pixel\n",
    "### Before Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[0])# prints the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As images are in Gray Level (1 channel=> 0 to 255), not colored (RGB)\n",
    "##### Normalizing the data | Pre-Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis =1 )\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after normalisation, the matrix looks like this\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizing the image to make it suitable for applying Convolution operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "IMG_SIZE = 28\n",
    "x_trainr = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE,1)\n",
    "## increasing one dimension for kernel operation\n",
    "x_testr = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE,1)\n",
    "print(\"Training Samples Dimension\", x_trainr.shape)\n",
    "print(\"Testing Samples Dimension\", x_testr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Deep Neural Network\n",
    "##### Training on 60k samples of MNIST handwritten dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a neural network now\n",
    "model = Sequential()\n",
    "\n",
    "### First Convolution Layer 0 1 2 3 (60000, 28, 28, 1)\n",
    "model.add(Conv2D(64, (3,3), input_shape = x_trainr.shape[1:]))\n",
    "## only for the first convolution layer to mention input layer size\n",
    "model.add(Activation(\"relu\"))\n",
    "##activation function to make it non-linear, if<0 remove, if>0 keep\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "## maxpooling single maximum value of 2x2\n",
    "\n",
    "## 2nd Convoltion Layer\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "## 3rd Convolution Layer\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "## Fully connected layer #1 20x20 = 400\n",
    "model.add(Flatten()) ## before using fully connected layer, flatted 2D->1D\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "## Fully connected layer #2\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "## Fully connected layer #3\n",
    "\n",
    "model.add(Dense(10))# last dense layer must be equal to number of classes, 10 (0-9)\n",
    "model.add(Activation(\"softmax\"))\n",
    "# activation function is changed to softmax(class probabilities)\n",
    "\n",
    "#if binary classification, Dense(1) and Activation(\"sigmoid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total training samples: \", len(x_trainr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer= \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_trainr, y_train, epochs=5, validation_split=0.3)\n",
    "#training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if\n",
    "validation accuracy ~= accuracy -> thats good\n",
    "if val_accuracy < accuracy -> overfitting -> solution: dropout..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluating on testing data set\n",
    "test_loss, test_acc = model.evaluate(x_testr, y_test)\n",
    "print(\"Test Loss on 10,000 test samples\", test_loss)\n",
    "print(\"Validation Accuracy on 10,000 test samples\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([x_testr])\n",
    "# predictions = model.predict([x_test])\n",
    "## there is specialised method for efficiently saving your model,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)#these are predictions \n",
    "##based on  one hot encodeing so these are only arrays\n",
    "##containing softmax probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inorder to understand, convert the predictions from one\n",
    "# hot encoding, we need to use numpy for that\n",
    "print(np.argmax(predictions[0]))\n",
    "## so actually argmax will return the max value index and find\n",
    "## the value of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(predictions[6969]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[6969])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('image-1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(gray, (28,28), interpolation= cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "newimg = tf.keras.utils.normalize(resized, axis=1)\n",
    "# scaling 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "newimg = np.array(newimg).reshape(-1, IMG_SIZE, IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(newimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
